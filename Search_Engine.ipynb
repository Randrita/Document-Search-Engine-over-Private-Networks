{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Search-Engine",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install libmagic1\n",
        "!pip3 install python-magic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVPGo8AMB6rT",
        "outputId": "d4c4d98c-1db5-4450-b026-46ecc48ce878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libmagic-mgc\n",
            "Suggested packages:\n",
            "  file\n",
            "The following NEW packages will be installed:\n",
            "  libmagic-mgc libmagic1\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 252 kB of archives.\n",
            "After this operation, 5,214 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Fetched 252 kB in 2s (156 kB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 155455 files and directories currently installed.)\n",
            "Preparing to unpack .../libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.7/dist-packages (0.4.25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pickle\n",
        "from pprint import pprint\n",
        "from typing import Dict"
      ],
      "metadata": {
        "id": "CO1yWq9HFrW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_codecs = ['ascii', 'big5', 'big5hkscs', 'cp037', 'cp273', 'cp424', 'cp437', \n",
        "'cp500', 'cp720', 'cp737', 'cp775', 'cp850', 'cp852', 'cp855', 'cp856', 'cp857', \n",
        "'cp858', 'cp860', 'cp861', 'cp862', 'cp863', 'cp864', 'cp865', 'cp866', 'cp869', \n",
        "'cp874', 'cp875', 'cp932', 'cp949', 'cp950', 'cp1006', 'cp1026', 'cp1125', \n",
        "'cp1140', 'cp1250', 'cp1251', 'cp1252', 'cp1253', 'cp1254', 'cp1255', 'cp1256', \n",
        "'cp1257', 'cp1258', 'euc_jp', 'euc_jis_2004', 'euc_jisx0213', 'euc_kr', \n",
        "'gb2312', 'gbk', 'gb18030', 'hz', 'iso2022_jp', 'iso2022_jp_1', 'iso2022_jp_2', \n",
        "'iso2022_jp_2004', 'iso2022_jp_3', 'iso2022_jp_ext', 'iso2022_kr', 'latin_1', \n",
        "'iso8859_2', 'iso8859_3', 'iso8859_4', 'iso8859_5', 'iso8859_6', 'iso8859_7', \n",
        "'iso8859_8', 'iso8859_9', 'iso8859_10', 'iso8859_11', 'iso8859_13', \n",
        "'iso8859_14', 'iso8859_15', 'iso8859_16', 'johab', 'koi8_r', 'koi8_t', 'koi8_u', \n",
        "'kz1048', 'mac_cyrillic', 'mac_greek', 'mac_iceland', 'mac_latin2', 'mac_roman', \n",
        "'mac_turkish', 'ptcp154', 'shift_jis', 'shift_jis_2004', 'shift_jisx0213', \n",
        "'utf_32', 'utf_32_be', 'utf_32_le', 'utf_16', 'utf_16_be', 'utf_16_le', 'utf_7', \n",
        "'utf_8', 'utf_8_sig']\n",
        "\n",
        "def smart_decoded(blob):\n",
        "    result = \"\"\n",
        "    for i in range( len(blob) - 1 ):\n",
        "        b = blob[i:i+1]\n",
        "        for codec in all_codecs:\n",
        "            try:\n",
        "                d = b.decode(codec)\n",
        "                result += d\n",
        "                break\n",
        "            except:\n",
        "                continue\n",
        "    pattern = re.compile(r'\\\\x[0-9a-f][0-9a-f]')\n",
        "    s = str(result.encode('utf-8'))[2:-1]\n",
        "    result = str(re.sub(pattern, '', s))\n",
        "    result = str(re.sub('\\\\\\\\[a-z]', ' ', result))\n",
        "    return result"
      ],
      "metadata": {
        "id": "EZ58dFhNFOFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zMHGJqYFZbW"
      },
      "outputs": [],
      "source": [
        "class SearchEngine:\n",
        "    ''' Create a search engine object '''\n",
        "\n",
        "    def __init__(self, indexing='index.pkl'):\n",
        "        self.file_index = [] # directory listing returned by os.walk()\n",
        "        self.indexing = indexing\n",
        "\n",
        "\n",
        "    def create_new_index(self, values: Dict[str, str]) -> None:\n",
        "        ''' Create a new file index of the root; then save to self.file_index and to pickle file '''\n",
        "        root_path = values['PATH']\n",
        "        self.file_index: list = [(root, files) for root, dirs, files in os.walk(root_path) if files]\n",
        "\n",
        "        # save index to file\n",
        "        with open(self.indexing,'wb') as f:\n",
        "            pickle.dump(self.file_index, f)\n",
        "\n",
        "\n",
        "    def load_existing_index(self) -> None:\n",
        "        ''' Load an existing file index into the program '''\n",
        "        try:\n",
        "            with open(self.indexing,'rb') as f:\n",
        "                self.file_index = pickle.load(f)\n",
        "        except:\n",
        "            self.file_index = []\n",
        "\n",
        "\n",
        "    def search(self, values: Dict[str, str], smartdecode=True, write_output=False) -> None:\n",
        "        ''' Search for the term based on the type in the index; the types of search\n",
        "            include: contains, startswith, endswith; save the results to file '''\n",
        "        results = []\n",
        "        matches = 0\n",
        "        records = 0\n",
        "        term = values['TERM']\n",
        "\n",
        "        # search for matches and count results\n",
        "        for path, files in self.file_index:\n",
        "            for file in files:\n",
        "                records +=1\n",
        "                if (values.get('CONTAINS', False) and term.lower() in file.lower() or \n",
        "                    values.get('STARTSWITH', False) and file.lower().startswith(term.lower()) or \n",
        "                    values.get('ENDSWITH', False) and file.lower().endswith(term.lower())):\n",
        "\n",
        "                    result = os.path.join(path.replace('\\\\','/'), file)\n",
        "                    results.append(result)\n",
        "                    matches += 1\n",
        "                else:\n",
        "                    continue \n",
        "        \n",
        "        if write_output:\n",
        "            # save results to file\n",
        "            with open('search_results.txt','w') as f:\n",
        "                for row in results:\n",
        "                    f.write(row + '\\n')\n",
        "\n",
        "        return [ self.build_result(path, smartdecode=smartdecode) for path in results ], matches, records\n",
        "\n",
        "    def build_result(self, path, N=2048, smartdecode=True):\n",
        "        fileresult = {}\n",
        "        \n",
        "        head, tail = os.path.split(path)\n",
        "        blob=None\n",
        "        with open(path, 'rb') as f:\n",
        "            blob = f.read(N)\n",
        "        return {\n",
        "            'file': tail,\n",
        "            'location': head,\n",
        "            'content': {\n",
        "                'blob': smart_decoded(blob) if smartdecode else blob,\n",
        "                'data': self.content_aware(blob)\n",
        "            },\n",
        "        }\n",
        "        \n",
        "    \n",
        "    def content_aware(self, blob):\n",
        "        try:\n",
        "            import magic\n",
        "        except ImportError as ex:\n",
        "            return 'Python Magic library `python-magic` not found. Follow the instructions from here: https://github.com/ahupp/python-magic to install `python-magic` and libpython.'\n",
        "        magicencoding = magic.Magic(mime_encoding=True)\n",
        "        encoding = magicencoding.from_buffer(blob)\n",
        "        magicraw = magic.Magic(raw=True)\n",
        "        raw = magicraw.from_buffer(blob)\n",
        "        return { 'encoding': encoding, 'type': raw }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "se = SearchEngine()\n",
        "se.create_new_index({'PATH':'/content/'})\n",
        "result, matches, records = se.search({'CONTAINS': True, 'TERM': 'ind'}, smartdecode=True)\n",
        "\n",
        "print(f\"{matches} matches found from {records} records\\n\")\n",
        "pprint(result)"
      ],
      "metadata": {
        "id": "K_hjKb2oFgQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce23ce86-c755-443e-c56b-546609de5d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 matches found from 23 records\n",
            "\n",
            "[{'content': {'blob': ']q(X /content/q]q(X '\n",
            "                      'index.pklqXuntitledqefqX/content/.configq]q(X.last_survey_prompt.yamlqXgceq '\n",
            "                      'X.last_update_check.jsonq '\n",
            "                      'X.last_opt_in_prompt.yamlqX.metricsUUIDqX '\n",
            "                      'active_configq '\n",
            "                      'X.feature_flags_config.yamlqXconfig_sentinelqefqX/content/.config/configurationsq]qXconfig_defaultqafqX '\n",
            "                      '/content/.config/logs/2022.04.08q]q(X13.32.13.036412.logqX13.31.04.724542.logqX13.31.27.549996.logqX13.32.12.365197.logqX13.31.53.465513.logqX13.31.45.686476.logqefqX/content/sample_dataq]q(X '\n",
            "                      'README.mdq X '\n",
            "                      'anscombe.jsonq!Xcalifornia_housing_test.csvq\"Xmnist_train_small.csvq#Xcalifornia_housing_train.csvq$Xmnist_test.csvq%efq&e',\n",
            "              'data': {'encoding': 'binary', 'type': 'data'}},\n",
            "  'file': 'index.pkl',\n",
            "  'location': '/content'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7GwEIvXAMRJb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}